{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Country Name Country Code  \\\n",
      "0       Angola          AGO   \n",
      "1       Angola          AGO   \n",
      "2       Angola          AGO   \n",
      "3       Angola          AGO   \n",
      "4       Angola          AGO   \n",
      "\n",
      "                                      Indicator Name     Indicator Code  1960  \\\n",
      "0  Intentional homicides, female (per 100,000 fem...  VC.IHR.PSRC.FE.P5   NaN   \n",
      "1           Battle-related deaths (number of people)        VC.BTL.DETH   NaN   \n",
      "2          Voice and Accountability: Percentile Rank         VA.PER.RNK   NaN   \n",
      "3  Transport services (% of commercial service ex...  TX.VAL.TRAN.ZS.WT   NaN   \n",
      "4  Computer, communications and other services (%...  TX.VAL.OTHR.ZS.WT   NaN   \n",
      "\n",
      "   1961  1962  1963  1964  1965  ...       2015       2016       2017  \\\n",
      "0   NaN   NaN   NaN   NaN   NaN  ...        NaN        NaN        NaN   \n",
      "1   NaN   NaN   NaN   NaN   NaN  ...        NaN  25.000000  25.000000   \n",
      "2   NaN   NaN   NaN   NaN   NaN  ...  15.270936  16.748768  18.226601   \n",
      "3   NaN   NaN   NaN   NaN   NaN  ...   2.013874   4.590600   2.347390   \n",
      "4   NaN   NaN   NaN   NaN   NaN  ...   5.425357   7.798874   8.233131   \n",
      "\n",
      "        2018       2019       2020       2021       2022       2023  \\\n",
      "0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "1        NaN  25.000000  21.000000        NaN  20.000000        NaN   \n",
      "2  22.815535  25.120773  25.603865  24.154589  26.570047        NaN   \n",
      "3   4.421110   7.003774  12.732683  15.679087  23.496554  30.637505   \n",
      "4   9.394259   8.513262  63.071646  60.504332  52.586799  59.439164   \n",
      "\n",
      "   Unnamed: 68  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n",
      "\n",
      "[5 rows x 69 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path\n",
    "file_path = '/Users/kudzanaikutsanzira/Downloads/Data for the Capstone Project /API_Download_DS2_en_csv_v2_23907/API_Download_DS2_en_csv_v2_23907.csv'\n",
    "\n",
    "# Attempt to load the CSV with skiprows and delimiter specification\n",
    "df = pd.read_csv(file_path, skiprows=4, delimiter=',')\n",
    "\n",
    "# Display the first few rows of the data\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Country Name',\n",
       " 'Country Code',\n",
       " 'Indicator Name',\n",
       " 'Indicator Code',\n",
       " '1960',\n",
       " '1961',\n",
       " '1962',\n",
       " '1963',\n",
       " '1964',\n",
       " '1965',\n",
       " '1966',\n",
       " '1967',\n",
       " '1968',\n",
       " '1969',\n",
       " '1970',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1974',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '1978',\n",
       " '1979',\n",
       " '1980',\n",
       " '1981',\n",
       " '1982',\n",
       " '1983',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1987',\n",
       " '1988',\n",
       " '1989',\n",
       " '1990',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1999',\n",
       " '2000',\n",
       " '2001',\n",
       " '2002',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '2013',\n",
       " '2014',\n",
       " '2015',\n",
       " '2016',\n",
       " '2017',\n",
       " '2018',\n",
       " '2019',\n",
       " '2020',\n",
       " '2021',\n",
       " '2022',\n",
       " '2023',\n",
       " 'Unnamed: 68']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the columns of the dataframe\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country Name Country Code  \\\n",
      "5        Angola          AGO   \n",
      "6        Angola          AGO   \n",
      "7        Angola          AGO   \n",
      "12       Angola          AGO   \n",
      "13       Angola          AGO   \n",
      "\n",
      "                                       Indicator Name     Indicator Code  \\\n",
      "5   Merchandise exports by the reporting economy, ...  TX.VAL.MRCH.RS.ZS   \n",
      "6   Merchandise exports to low- and middle-income ...  TX.VAL.MRCH.R3.ZS   \n",
      "7   Merchandise exports to high-income economies (...  TX.VAL.MRCH.HI.ZS   \n",
      "12  Merchandise imports by the reporting economy (...  TM.VAL.MRCH.WL.CD   \n",
      "13  Merchandise imports from low- and middle-incom...  TM.VAL.MRCH.R4.ZS   \n",
      "\n",
      "    Year         Value  \n",
      "5   1960  4.136253e+00  \n",
      "6   1960  8.110300e-02  \n",
      "7   1960  8.775345e+01  \n",
      "12  1960  1.275000e+08  \n",
      "13  1960  4.705882e-01  \n"
     ]
    }
   ],
   "source": [
    "# Drop the unnecessary column\n",
    "df = df.drop(columns=['Unnamed: 68'])\n",
    "\n",
    "# Reshape the dataset to a tidy format\n",
    "df_tidy = df.melt(id_vars=['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code'],\n",
    "                      var_name='Year', value_name='Value')\n",
    "\n",
    "# Convert 'Year' to a numeric type for easier filtering and plotting\n",
    "df_tidy['Year'] = pd.to_numeric(df_tidy['Year'], errors='coerce')\n",
    "\n",
    "# Handle missing values (example: drop rows with missing values in 'Value' column)\n",
    "df_tidy = df_tidy.dropna(subset=['Value'])\n",
    "\n",
    "# Preview the cleaned data\n",
    "print(df_tidy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "1960    17260\n",
      "1961    16969\n",
      "1962    16917\n",
      "1963    16848\n",
      "1964    16714\n",
      "        ...  \n",
      "2019     6270\n",
      "2020     7453\n",
      "2021     8040\n",
      "2022     9727\n",
      "2023    14911\n",
      "Length: 64, dtype: int64\n",
      "\n",
      "Percentage of missing values per column:\n",
      "1960    88.749486\n",
      "1961    87.253188\n",
      "1962    86.985808\n",
      "1963    86.631016\n",
      "1964    85.941999\n",
      "          ...    \n",
      "2019    32.239819\n",
      "2020    38.322707\n",
      "2021    41.341012\n",
      "2022    50.015426\n",
      "2023    76.671123\n",
      "Length: 64, dtype: float64\n",
      "\n",
      "Missing values in 'Value' column of tidy data: 737608\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values across all columns\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Display columns with missing values and their counts\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Check percentage of missing values to understand the extent\n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "print(\"\\nPercentage of missing values per column:\")\n",
    "print(missing_percentage[missing_percentage > 0])\n",
    "\n",
    "# Analyze missing data in the reshaped 'df_tidy' (after running the melt transformation)\n",
    "df_tidy = df.melt(id_vars=['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code'],\n",
    "                  var_name='Year', value_name='Value')\n",
    "missing_tidy = df_tidy['Value'].isnull().sum()\n",
    "print(f\"\\nMissing values in 'Value' column of tidy data: {missing_tidy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Creating Class to encapsulate\n",
    "class DataFrameOperations:\n",
    "    def convert_columns_lower(self, sheet_df):\n",
    "        logging.info(\"Converting Columns to Lowercase\")\n",
    "        sheet_df.columns = sheet_df.columns.str.replace(' ', '_').str.replace(r'(?<!^)(?=[A-Z])', '_').str.lower()\n",
    "        return sheet_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " def remove_duplicates(self, sheet_df, columns):\n",
    "        logging.info(f\"Duplicates before removal: {sheet_df.duplicated(subset=columns, keep='first').sum()}\")\t\n",
    "        sheet_df.drop_duplicates(subset=columns, keep='first', inplace=True)\n",
    "        return sheet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unused_columns(self, sheet_df, columns):\n",
    "        logging.info(f\"Removing Columns: {columns}\")\n",
    "        sheet_df.drop(columns, axis=1, inplace=True, errors='ignore')\n",
    "        return sheet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_data(self, sheet_df, id_vars, var_name, value_name):\n",
    "        logging.info(\"Melting Data\")\n",
    "        sheet_df = pd.melt(sheet_df, id_vars=id_vars, var_name=var_name, value_name=value_name)\n",
    "        logging.info(f\"Columns after Melting Data: {sheet_df.columns}\")\n",
    "        return sheet_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " def replace_colvalues(self, sheet_df, columns):\n",
    "        logging.info(f\"Before Replacing Column Values: {sheet_df[columns].head(1)}\")\n",
    "        sheet_df[columns] = sheet_df[columns].str.replace(r\"(\\d{4})_\\[yr\\d{4}\\]\", r\"\\1\", regex=True)\n",
    "        logging.info(f\"After Replacing Column Values: {sheet_df[columns].head(1)}\")\n",
    "        return sheet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " def interpolate_na_rows(self, sheet_df, columns):\n",
    "        logging.info(f\"Interpolating N/A Columns: {columns}\")\n",
    "        sheet_df[columns].interpolate(method='polynomial', order=2, inplace=True)\n",
    "        return sheet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data_types(self, sheet_df, columns):\n",
    "        logging.info(\"Standardizing Data Types\")\n",
    "        for column, dtype in columns.items():\n",
    "            if column in sheet_df.columns:\n",
    "                sheet_df[column] = sheet_df[column].astype(dtype)\n",
    "        return sheet_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " def convert_datetime(self, sheet_df, columns):\n",
    "        logging.info(f\"Converting Datetime Columns: {columns}\")\n",
    "        sheet_df[columns] = pd.to_datetime(sheet_df[columns], dayfirst=True)\n",
    "        return sheet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the class\n",
    "df_ops = DataFrameOperations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to be used for data cleaning\n",
    "columns = {\n",
    "    'Year': 'int64',\n",
    "    'Value': 'float64'\n",
    "}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
